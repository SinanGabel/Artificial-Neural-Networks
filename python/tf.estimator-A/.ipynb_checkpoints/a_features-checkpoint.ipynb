{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/04_features/a_features.ipynb\n",
    "\n",
    "Nearly same source example: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/05_artandscience/a_handtuning.ipynb\n",
    "\n",
    "I have made some changes to the original source notebook.\n",
    "\n",
    "You can run this notebook in Google Cloud Datalab.\n",
    "\n",
    "If you want to run this notebook in jupyter you may have to install google.datalab.ml for tensorboard, see how: https://github.com/googledatalab/pydatalab\n",
    "\n",
    "Versions: I have tried this notebook with Google Cloud Datalab with tensorflow 1.8, and jupyter with tensorflow 1.12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Results will differ to run to run.\n",
    "\n",
    "(1) Best result of four quick runs using four different estimators:\n",
    "\n",
    "estimator = tf.estimator.DNNRegressor(model_dir = output_dir, \n",
    "                                        feature_columns=create_feature_cols(), \n",
    "                                        hidden_units=[128, 64, 16], \n",
    "                                        activation_fn=tf.nn.tanh, \n",
    "                                        dropout=0.25)\n",
    "\n",
    "global step 5000: average_loss = 0.4656095, global_step = 5000, loss = 58.42537\n",
    "\n",
    "global step 20000: average_loss = 0.48848036, global_step = 20000, label/mean = 2.0454628, loss = 61.29524, prediction/mean = 1.7932605\n",
    "\n",
    "(2)  LinearRegressor\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(model_dir = output_dir, feature_columns = create_feature_cols())\n",
    "\n",
    "global step 2000: average_loss = 0.6363067, global_step = 2000, loss = 79.84471\n",
    "\n",
    "(3) LinearRegressor with another optimizer: tf.train.FtrlOptimizer()\n",
    "\n",
    "global step 5000: average_loss = 0.63224727, global_step = 5000, label/mean = 2.0454626, loss = 79.33532, prediction/mean = 1.8826075\n",
    "\n",
    "(4) DNNRegressor: 256,...\n",
    "\n",
    "estimator = tf.estimator.DNNRegressor(model_dir = output_dir, feature_columns=create_feature_cols(), hidden_units=[256, 128, 64])\n",
    "\n",
    "global step 2000: average_loss = 0.5527556, global_step = 2000, loss = 69.36059\n",
    "\n",
    "(5) DNNRegressor: 512, ...\n",
    "\n",
    "estimator = tf.estimator.DNNRegressor(model_dir = output_dir, feature_columns=create_feature_cols(), hidden_units=[512, 256, 64], dropout=0.25)\n",
    "\n",
    "global step 5000: average_loss = 0.9650534, global_step = 5000, loss = 121.09633\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Trying out features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "  * Improve the accuracy of a model by adding new features with the appropriate representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Set Up\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from google.datalab.ml import TensorBoard\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "df = pd.read_csv(\"data/california_housing_train.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Examine and split the data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column.\n",
    "\n",
    "This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1     -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2     -114.6      33.7                17.0        720.0           174.0   \n",
       "3     -114.6      33.6                14.0       1501.0           337.0   \n",
       "4     -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0            1.5             66900.0  \n",
       "1      1129.0       463.0            1.8             80100.0  \n",
       "2       333.0       117.0            1.7             85700.0  \n",
       "3       515.0       226.0            3.2             73400.0  \n",
       "4       624.0       262.0            1.9             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9            207300.9  \n",
       "std        1147.9       384.5            1.9            115983.8  \n",
       "min           3.0         1.0            0.5             14999.0  \n",
       "25%         790.0       282.0            2.6            119400.0  \n",
       "50%        1167.0       409.0            3.5            180400.0  \n",
       "75%        1721.0       605.2            4.8            265000.0  \n",
       "max       35682.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, split the data into two parts -- training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1) #makes result reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "      <td>13612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.7</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>1423.3</td>\n",
       "      <td>498.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207986.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2163.3</td>\n",
       "      <td>416.7</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>379.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>116514.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2117.5</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>180800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3146.0</td>\n",
       "      <td>644.2</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>266300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>5189.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    13612.0   13612.0             13612.0      13612.0         13612.0   \n",
       "mean      -119.6      35.6                28.7       2632.0           536.0   \n",
       "std          2.0       2.1                12.6       2163.3           416.7   \n",
       "min       -124.3      32.5                 1.0          8.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1461.0           296.0   \n",
       "50%       -118.5      34.2                29.0       2117.5           432.0   \n",
       "75%       -118.0      37.7                37.0       3146.0           644.2   \n",
       "max       -114.3      42.0                52.0      37937.0          5471.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     13612.0     13612.0        13612.0             13612.0  \n",
       "mean       1423.3       498.1            3.9            207986.5  \n",
       "std        1126.0       379.3            1.9            116514.3  \n",
       "min           3.0         1.0            0.5             14999.0  \n",
       "25%         787.0       281.0            2.6            119600.0  \n",
       "50%        1168.0       408.0            3.6            180800.0  \n",
       "75%        1715.0       602.0            4.8            266300.0  \n",
       "max       35682.0      5189.0           15.0            500001.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>3388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.7</td>\n",
       "      <td>28.3</td>\n",
       "      <td>2690.4</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1454.8</td>\n",
       "      <td>513.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>204546.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2245.5</td>\n",
       "      <td>440.2</td>\n",
       "      <td>1231.5</td>\n",
       "      <td>404.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>113802.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>283.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>118800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.6</td>\n",
       "      <td>34.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2171.5</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>178650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3167.2</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1756.2</td>\n",
       "      <td>615.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>258825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>41.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>32627.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>28566.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count     3388.0    3388.0              3388.0       3388.0          3388.0   \n",
       "mean      -119.6      35.7                28.3       2690.4           553.0   \n",
       "std          2.0       2.1                12.6       2245.5           440.2   \n",
       "min       -124.3      32.5                 2.0          2.0             2.0   \n",
       "25%       -121.8      33.9                18.0       1467.0           300.0   \n",
       "50%       -118.6      34.3                28.0       2171.5           441.0   \n",
       "75%       -118.0      37.7                37.0       3167.2           667.0   \n",
       "max       -114.6      41.9                52.0      32627.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count      3388.0      3388.0         3388.0              3388.0  \n",
       "mean       1454.8       513.7            3.8            204546.3  \n",
       "std        1231.5       404.7            1.8            113802.5  \n",
       "min           6.0         2.0            0.5             22500.0  \n",
       "25%         796.0       283.8            2.5            118800.0  \n",
       "50%        1160.0       414.0            3.5            178650.0  \n",
       "75%        1756.2       615.2            4.7            258825.0  \n",
       "max       28566.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "In this exercise, we'll be trying to predict **median_house_value** It will be our label (sometimes also called a target).\n",
    "\n",
    "We'll modify the feature_cols and input function to represent the features you want to use.\n",
    "\n",
    "Note: total_rooms is per block so to get rooms per house, and other, we need make some transformations.\n",
    "\n",
    "We divide **total_rooms** by **households** to get **avg_rooms_per_house** which we excect to positively correlate with **median_house_value**. \n",
    "\n",
    "We also divide **population** by **total_rooms** to get **avg_persons_per_room** which we expect to negatively correlate with **median_house_value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_features(df):\n",
    "  df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] #expect positive correlation\n",
    "  df['avg_persons_per_room'] = df['population'] / df['total_rooms'] #expect negative correlation\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_more_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas input function: returns function, that has signature of () -> (dict of features, target)\n",
    "SCALE=100000\n",
    "\n",
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = add_more_features(df),\n",
    "    #x = df,  \n",
    "    y = df['median_house_value'] / SCALE, # will talk about why later in the course\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "  return [\n",
    "    tf.feature_column.numeric_column('housing_median_age'),\n",
    "    tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), boundaries = np.arange(32.0, 42, 1).tolist()),\n",
    "    tf.feature_column.numeric_column('avg_rooms_per_house'),\n",
    "    tf.feature_column.numeric_column('avg_persons_per_room'),\n",
    "    tf.feature_column.numeric_column('median_income')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a model ...\n",
    "\n",
    "## LinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note LinearRegressor default loss: loss is calculated by using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(model_dir = output_dir, feature_columns = create_feature_cols())\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(model_dir = output_dir, \n",
    "                                           feature_columns = create_feature_cols(),\n",
    "                                           optimizer=tf.train.FtrlOptimizer(learning_rate=0.1, l1_regularization_strength=0.001))\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNNRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note DNNRegressor default loss: loss is calculated by using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "\n",
    "  estimator = tf.estimator.DNNRegressor(model_dir = output_dir, \n",
    "                                        feature_columns=create_feature_cols(), \n",
    "                                        hidden_units=[128, 64, 16], \n",
    "                                        activation_fn=tf.nn.tanh, \n",
    "                                        dropout=0.25)\n",
    "  \n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "\n",
    "  estimator = tf.estimator.DNNRegressor(model_dir = output_dir, \n",
    "                                        feature_columns=create_feature_cols(), \n",
    "                                        hidden_units=[128, 64, 16], \n",
    "                                        activation_fn=tf.nn.tanh, \n",
    "                                        dropout=0.25,\n",
    "                                        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.1,l1_regularization_strength=0.001))\n",
    "  \n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try add RMSE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "\n",
    "  estimator = tf.estimator.DNNRegressor(model_dir = output_dir, \n",
    "                                        feature_columns=create_feature_cols(), \n",
    "                                        hidden_units=[128, 64, 16], \n",
    "                                        activation_fn=tf.nn.tanh, \n",
    "                                        dropout=0.25)\n",
    "\n",
    "  # --- Add RMSE evaluation metric: it is simply the square root of the default metric: MSE ---\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'], tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)}\n",
    "  \n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  # --- continue ---\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "                                      max_steps = num_train_steps)\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "                                    steps = None, \n",
    "                                    start_delay_secs = 1, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 5)  # evaluate every N seconds\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = './trained_model'\n",
    "\n",
    "try:\n",
    "  os.makedirs(OUTDIR)\n",
    "except OSError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd682fad588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 882.97577, step = 1\n",
      "INFO:tensorflow:global_step/sec: 223.607\n",
      "INFO:tensorflow:loss = 270.9191, step = 101 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.619\n",
      "INFO:tensorflow:loss = 214.13982, step = 201 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.015\n",
      "INFO:tensorflow:loss = 125.45847, step = 301 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.062\n",
      "INFO:tensorflow:loss = 104.59697, step = 401 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.35\n",
      "INFO:tensorflow:loss = 77.71553, step = 501 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.295\n",
      "INFO:tensorflow:loss = 49.549446, step = 601 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.792\n",
      "INFO:tensorflow:loss = 52.756283, step = 701 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.735\n",
      "INFO:tensorflow:loss = 111.70557, step = 801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.297\n",
      "INFO:tensorflow:loss = 169.39351, step = 901 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.198\n",
      "INFO:tensorflow:loss = 133.75748, step = 1001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.778\n",
      "INFO:tensorflow:loss = 96.62508, step = 1101 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.442\n",
      "INFO:tensorflow:loss = 68.90434, step = 1201 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.706\n",
      "INFO:tensorflow:loss = 79.90011, step = 1301 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.701\n",
      "INFO:tensorflow:loss = 100.897995, step = 1401 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.372\n",
      "INFO:tensorflow:loss = 94.087875, step = 1501 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.527\n",
      "INFO:tensorflow:loss = 99.27806, step = 1601 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.576\n",
      "INFO:tensorflow:loss = 65.41512, step = 1701 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.015\n",
      "INFO:tensorflow:loss = 78.369705, step = 1801 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.794\n",
      "INFO:tensorflow:loss = 105.549484, step = 1901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.338\n",
      "INFO:tensorflow:loss = 79.36047, step = 2001 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.906\n",
      "INFO:tensorflow:loss = 71.51619, step = 2101 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.305\n",
      "INFO:tensorflow:loss = 79.99061, step = 2201 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.752\n",
      "INFO:tensorflow:loss = 44.10567, step = 2301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.476\n",
      "INFO:tensorflow:loss = 84.13101, step = 2401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.634\n",
      "INFO:tensorflow:loss = 101.02226, step = 2501 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.4\n",
      "INFO:tensorflow:loss = 138.98856, step = 2601 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.548\n",
      "INFO:tensorflow:loss = 81.17146, step = 2701 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.729\n",
      "INFO:tensorflow:loss = 43.565365, step = 2801 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.906\n",
      "INFO:tensorflow:loss = 52.05436, step = 2901 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.782\n",
      "INFO:tensorflow:loss = 55.51336, step = 3001 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.612\n",
      "INFO:tensorflow:loss = 90.52919, step = 3101 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.12\n",
      "INFO:tensorflow:loss = 99.7829, step = 3201 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.017\n",
      "INFO:tensorflow:loss = 78.480606, step = 3301 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.812\n",
      "INFO:tensorflow:loss = 68.51048, step = 3401 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.418\n",
      "INFO:tensorflow:loss = 91.82364, step = 3501 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.507\n",
      "INFO:tensorflow:loss = 66.24835, step = 3601 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.349\n",
      "INFO:tensorflow:loss = 81.84511, step = 3701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.827\n",
      "INFO:tensorflow:loss = 70.6694, step = 3801 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.169\n",
      "INFO:tensorflow:loss = 33.337524, step = 3901 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.555\n",
      "INFO:tensorflow:loss = 45.43936, step = 4001 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.499\n",
      "INFO:tensorflow:loss = 85.73715, step = 4101 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.345\n",
      "INFO:tensorflow:loss = 84.48335, step = 4201 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.118\n",
      "INFO:tensorflow:loss = 123.251816, step = 4301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.445\n",
      "INFO:tensorflow:loss = 82.59602, step = 4401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.425\n",
      "INFO:tensorflow:loss = 67.6711, step = 4501 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.09\n",
      "INFO:tensorflow:loss = 70.56603, step = 4601 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.81\n",
      "INFO:tensorflow:loss = 45.789707, step = 4701 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.805\n",
      "INFO:tensorflow:loss = 72.71639, step = 4801 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.778\n",
      "INFO:tensorflow:loss = 65.284615, step = 4901 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.901\n",
      "INFO:tensorflow:loss = 37.935326, step = 5001 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.679\n",
      "INFO:tensorflow:loss = 86.754196, step = 5101 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.646\n",
      "INFO:tensorflow:loss = 89.77835, step = 5201 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.226\n",
      "INFO:tensorflow:loss = 50.9205, step = 5301 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.661\n",
      "INFO:tensorflow:loss = 76.50836, step = 5401 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.295\n",
      "INFO:tensorflow:loss = 86.11281, step = 5501 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.054\n",
      "INFO:tensorflow:loss = 27.981827, step = 5601 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.256\n",
      "INFO:tensorflow:loss = 56.89866, step = 5701 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.324\n",
      "INFO:tensorflow:loss = 54.532547, step = 5801 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.756\n",
      "INFO:tensorflow:loss = 94.41848, step = 5901 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.735\n",
      "INFO:tensorflow:loss = 106.11411, step = 6001 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.241\n",
      "INFO:tensorflow:loss = 73.30657, step = 6101 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.564\n",
      "INFO:tensorflow:loss = 45.447147, step = 6201 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.873\n",
      "INFO:tensorflow:loss = 45.926964, step = 6301 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.353\n",
      "INFO:tensorflow:loss = 51.75944, step = 6401 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.979\n",
      "INFO:tensorflow:loss = 75.50543, step = 6501 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.539\n",
      "INFO:tensorflow:loss = 76.54932, step = 6601 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.417\n",
      "INFO:tensorflow:loss = 50.05076, step = 6701 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.564\n",
      "INFO:tensorflow:loss = 101.90869, step = 6801 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.745\n",
      "INFO:tensorflow:loss = 105.806656, step = 6901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.719\n",
      "INFO:tensorflow:loss = 77.25887, step = 7001 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.789\n",
      "INFO:tensorflow:loss = 75.090546, step = 7101 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.387\n",
      "INFO:tensorflow:loss = 52.033775, step = 7201 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.186\n",
      "INFO:tensorflow:loss = 40.14402, step = 7301 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.165\n",
      "INFO:tensorflow:loss = 63.53904, step = 7401 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.567\n",
      "INFO:tensorflow:loss = 57.820904, step = 7501 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.375\n",
      "INFO:tensorflow:loss = 106.433975, step = 7601 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.585\n",
      "INFO:tensorflow:loss = 91.72905, step = 7701 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.875\n",
      "INFO:tensorflow:loss = 47.272095, step = 7801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.513\n",
      "INFO:tensorflow:loss = 40.000313, step = 7901 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.278\n",
      "INFO:tensorflow:loss = 44.065662, step = 8001 (0.454 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 230.531\n",
      "INFO:tensorflow:loss = 43.960896, step = 8101 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.308\n",
      "INFO:tensorflow:loss = 72.56143, step = 8201 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.479\n",
      "INFO:tensorflow:loss = 65.373726, step = 8301 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.295\n",
      "INFO:tensorflow:loss = 39.92888, step = 8401 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.339\n",
      "INFO:tensorflow:loss = 38.483463, step = 8501 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.403\n",
      "INFO:tensorflow:loss = 95.87021, step = 8601 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.33\n",
      "INFO:tensorflow:loss = 74.809074, step = 8701 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.695\n",
      "INFO:tensorflow:loss = 59.376846, step = 8801 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.378\n",
      "INFO:tensorflow:loss = 53.785503, step = 8901 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.565\n",
      "INFO:tensorflow:loss = 32.991783, step = 9001 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.147\n",
      "INFO:tensorflow:loss = 63.04695, step = 9101 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.483\n",
      "INFO:tensorflow:loss = 41.620117, step = 9201 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.753\n",
      "INFO:tensorflow:loss = 86.08294, step = 9301 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.926\n",
      "INFO:tensorflow:loss = 60.729286, step = 9401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.198\n",
      "INFO:tensorflow:loss = 39.742783, step = 9501 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.497\n",
      "INFO:tensorflow:loss = 35.663437, step = 9601 (0.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.485\n",
      "INFO:tensorflow:loss = 55.533184, step = 9701 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.635\n",
      "INFO:tensorflow:loss = 53.2579, step = 9801 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.912\n",
      "INFO:tensorflow:loss = 83.66676, step = 9901 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.533\n",
      "INFO:tensorflow:loss = 55.81818, step = 10001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.812\n",
      "INFO:tensorflow:loss = 62.471275, step = 10101 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.931\n",
      "INFO:tensorflow:loss = 54.307457, step = 10201 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.497\n",
      "INFO:tensorflow:loss = 65.075226, step = 10301 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.734\n",
      "INFO:tensorflow:loss = 75.21402, step = 10401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.211\n",
      "INFO:tensorflow:loss = 64.28375, step = 10501 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.419\n",
      "INFO:tensorflow:loss = 37.99686, step = 10601 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.787\n",
      "INFO:tensorflow:loss = 46.138752, step = 10701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.079\n",
      "INFO:tensorflow:loss = 58.793774, step = 10801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.241\n",
      "INFO:tensorflow:loss = 47.70802, step = 10901 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.694\n",
      "INFO:tensorflow:loss = 85.15114, step = 11001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.661\n",
      "INFO:tensorflow:loss = 79.05524, step = 11101 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.781\n",
      "INFO:tensorflow:loss = 32.512947, step = 11201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.307\n",
      "INFO:tensorflow:loss = 49.84808, step = 11301 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.759\n",
      "INFO:tensorflow:loss = 57.149025, step = 11401 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.073\n",
      "INFO:tensorflow:loss = 80.499695, step = 11501 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.391\n",
      "INFO:tensorflow:loss = 57.90884, step = 11601 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.382\n",
      "INFO:tensorflow:loss = 62.152565, step = 11701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.806\n",
      "INFO:tensorflow:loss = 57.998848, step = 11801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.703\n",
      "INFO:tensorflow:loss = 56.075554, step = 11901 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.655\n",
      "INFO:tensorflow:loss = 56.934517, step = 12001 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.687\n",
      "INFO:tensorflow:loss = 58.822933, step = 12101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.866\n",
      "INFO:tensorflow:loss = 79.03178, step = 12201 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.612\n",
      "INFO:tensorflow:loss = 31.169113, step = 12301 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.779\n",
      "INFO:tensorflow:loss = 34.75761, step = 12401 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.889\n",
      "INFO:tensorflow:loss = 53.363716, step = 12501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.209\n",
      "INFO:tensorflow:loss = 76.46176, step = 12601 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.617\n",
      "INFO:tensorflow:loss = 71.17398, step = 12701 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 229\n",
      "INFO:tensorflow:loss = 87.75204, step = 12801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.98\n",
      "INFO:tensorflow:loss = 29.909506, step = 12901 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.314\n",
      "INFO:tensorflow:loss = 39.09472, step = 13001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.939\n",
      "INFO:tensorflow:loss = 51.63574, step = 13101 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.39\n",
      "INFO:tensorflow:loss = 81.41789, step = 13201 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.18\n",
      "INFO:tensorflow:loss = 81.77841, step = 13301 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.126\n",
      "INFO:tensorflow:loss = 25.015434, step = 13401 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.994\n",
      "INFO:tensorflow:loss = 78.47534, step = 13501 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.7\n",
      "INFO:tensorflow:loss = 92.195984, step = 13601 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.311\n",
      "INFO:tensorflow:loss = 75.80817, step = 13701 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.946\n",
      "INFO:tensorflow:loss = 55.44529, step = 13801 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.571\n",
      "INFO:tensorflow:loss = 51.006622, step = 13901 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.847\n",
      "INFO:tensorflow:loss = 27.200113, step = 14001 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.869\n",
      "INFO:tensorflow:loss = 56.051537, step = 14101 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.757\n",
      "INFO:tensorflow:loss = 35.31594, step = 14201 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.667\n",
      "INFO:tensorflow:loss = 77.470825, step = 14301 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.659\n",
      "INFO:tensorflow:loss = 72.64806, step = 14401 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.529\n",
      "INFO:tensorflow:loss = 67.135925, step = 14501 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.852\n",
      "INFO:tensorflow:loss = 26.366013, step = 14601 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.808\n",
      "INFO:tensorflow:loss = 36.19757, step = 14701 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.858\n",
      "INFO:tensorflow:loss = 44.961372, step = 14801 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.312\n",
      "INFO:tensorflow:loss = 43.171227, step = 14901 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.269\n",
      "INFO:tensorflow:loss = 66.82159, step = 15001 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.015\n",
      "INFO:tensorflow:loss = 42.840347, step = 15101 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.93\n",
      "INFO:tensorflow:loss = 31.304745, step = 15201 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.261\n",
      "INFO:tensorflow:loss = 74.00332, step = 15301 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.242\n",
      "INFO:tensorflow:loss = 59.227634, step = 15401 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.544\n",
      "INFO:tensorflow:loss = 57.58509, step = 15501 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.161\n",
      "INFO:tensorflow:loss = 43.414925, step = 15601 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.625\n",
      "INFO:tensorflow:loss = 38.63279, step = 15701 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.407\n",
      "INFO:tensorflow:loss = 50.209396, step = 15801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.226\n",
      "INFO:tensorflow:loss = 72.190094, step = 15901 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.736\n",
      "INFO:tensorflow:loss = 81.58825, step = 16001 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.138\n",
      "INFO:tensorflow:loss = 74.11324, step = 16101 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.83\n",
      "INFO:tensorflow:loss = 44.401707, step = 16201 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.618\n",
      "INFO:tensorflow:loss = 37.06613, step = 16301 (0.471 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 234.524\n",
      "INFO:tensorflow:loss = 48.309837, step = 16401 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.565\n",
      "INFO:tensorflow:loss = 61.976135, step = 16501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.049\n",
      "INFO:tensorflow:loss = 53.851505, step = 16601 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.184\n",
      "INFO:tensorflow:loss = 43.822807, step = 16701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.231\n",
      "INFO:tensorflow:loss = 66.63858, step = 16801 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.827\n",
      "INFO:tensorflow:loss = 63.06395, step = 16901 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.331\n",
      "INFO:tensorflow:loss = 63.905563, step = 17001 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.584\n",
      "INFO:tensorflow:loss = 52.571236, step = 17101 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.264\n",
      "INFO:tensorflow:loss = 54.388195, step = 17201 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.078\n",
      "INFO:tensorflow:loss = 47.497406, step = 17301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.6\n",
      "INFO:tensorflow:loss = 40.650127, step = 17401 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.977\n",
      "INFO:tensorflow:loss = 32.662773, step = 17501 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.022\n",
      "INFO:tensorflow:loss = 66.02318, step = 17601 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.317\n",
      "INFO:tensorflow:loss = 90.95956, step = 17701 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.35\n",
      "INFO:tensorflow:loss = 59.214653, step = 17801 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.615\n",
      "INFO:tensorflow:loss = 39.94174, step = 17901 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.953\n",
      "INFO:tensorflow:loss = 70.88565, step = 18001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.864\n",
      "INFO:tensorflow:loss = 42.246223, step = 18101 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.279\n",
      "INFO:tensorflow:loss = 66.149, step = 18201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.204\n",
      "INFO:tensorflow:loss = 85.524925, step = 18301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.75\n",
      "INFO:tensorflow:loss = 37.617622, step = 18401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.606\n",
      "INFO:tensorflow:loss = 43.616318, step = 18501 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.199\n",
      "INFO:tensorflow:loss = 64.986206, step = 18601 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.639\n",
      "INFO:tensorflow:loss = 41.340607, step = 18701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.089\n",
      "INFO:tensorflow:loss = 74.88318, step = 18801 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.736\n",
      "INFO:tensorflow:loss = 55.92324, step = 18901 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.93\n",
      "INFO:tensorflow:loss = 27.5732, step = 19001 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.281\n",
      "INFO:tensorflow:loss = 55.000725, step = 19101 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.593\n",
      "INFO:tensorflow:loss = 35.118366, step = 19201 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.922\n",
      "INFO:tensorflow:loss = 64.36455, step = 19301 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.263\n",
      "INFO:tensorflow:loss = 59.06331, step = 19401 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.468\n",
      "INFO:tensorflow:loss = 75.442955, step = 19501 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.116\n",
      "INFO:tensorflow:loss = 29.380453, step = 19601 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.915\n",
      "INFO:tensorflow:loss = 77.82637, step = 19701 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.165\n",
      "INFO:tensorflow:loss = 39.18415, step = 19801 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.299\n",
      "INFO:tensorflow:loss = 70.05841, step = 19901 (0.423 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-23-17:18:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-23-17:18:49\n",
      "INFO:tensorflow:Saving dict for global step 20000: average_loss = 0.48848036, global_step = 20000, label/mean = 2.0454628, loss = 61.29524, prediction/mean = 1.7932605\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: ./trained_model/model.ckpt-20000\n",
      "INFO:tensorflow:Loss for final step: 54.527557.\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True)\n",
    "\n",
    "train_and_evaluate(OUTDIR, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 18179. Click <a href=\"/_proxy/34675/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18179"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch tensorboard\n",
    "\n",
    "# Note: If you use jupyter then you may have to use the address shown in the terminal console instead of the below link to tensorboard.\n",
    "\n",
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
